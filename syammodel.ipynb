{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pAViw_KVjonw",
        "outputId": "02e8eb05-4c9f-4d56-8884-6363557de61f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.7815 - loss: 0.6340 - val_accuracy: 0.8420 - val_loss: 0.4407\n",
            "Epoch 2/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.8623 - loss: 0.3840 - val_accuracy: 0.8647 - val_loss: 0.3776\n",
            "Epoch 3/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8771 - loss: 0.3347 - val_accuracy: 0.8719 - val_loss: 0.3632\n",
            "Epoch 4/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8817 - loss: 0.3185 - val_accuracy: 0.8512 - val_loss: 0.4079\n",
            "Epoch 5/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.8899 - loss: 0.2988 - val_accuracy: 0.8730 - val_loss: 0.3521\n",
            "Epoch 6/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8961 - loss: 0.2815 - val_accuracy: 0.8653 - val_loss: 0.3823\n",
            "Epoch 7/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.9021 - loss: 0.2679 - val_accuracy: 0.8749 - val_loss: 0.3493\n",
            "Epoch 8/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9057 - loss: 0.2533 - val_accuracy: 0.8833 - val_loss: 0.3297\n",
            "Epoch 9/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9083 - loss: 0.2454 - val_accuracy: 0.8868 - val_loss: 0.3266\n",
            "Epoch 10/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9147 - loss: 0.2328 - val_accuracy: 0.8859 - val_loss: 0.3270\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training , save mode to syam_model.h5, syam_model.npz, syam_model.json\n",
            "Test accuracy: 0.8859 disimpan di test_accuracy.txt\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "OUTPUT_FILE = 'test_accuracy.txt'\n",
        "\n",
        "def softmax(x):\n",
        "    e_x = np.exp(x - np.max(x, axis=-1, keepdims=True))\n",
        "    return e_x / np.sum(e_x, axis=-1, keepdims=True)\n",
        "\n",
        "def load_test_acc():\n",
        "    acc = 0\n",
        "    try:\n",
        "        with open(OUTPUT_FILE, 'r') as file:\n",
        "            line = file.readline()\n",
        "            acc = float(line.strip())\n",
        "    except Exception as e:\n",
        "        print(\"Error! \", e)\n",
        "    return acc\n",
        "\n",
        "def test_acc_80():\n",
        "    acc = load_test_acc()\n",
        "    assert acc >= 0.8\n",
        "\n",
        "def test_acc_82():\n",
        "    acc = load_test_acc()\n",
        "    assert acc >= 0.82\n",
        "\n",
        "def test_acc_84():\n",
        "    acc = load_test_acc()\n",
        "    assert acc >= 0.84\n",
        "\n",
        "def test_acc_86():\n",
        "    acc = load_test_acc()\n",
        "    assert acc >= 0.86\n",
        "\n",
        "def test_acc_88():\n",
        "    acc = load_test_acc()\n",
        "    assert acc >= 0.88\n",
        "\n",
        "def test_acc_90():\n",
        "    acc = load_test_acc()\n",
        "    assert acc >= 0.9\n",
        "\n",
        "def test_acc_91():\n",
        "    acc = load_test_acc()\n",
        "    assert acc >= 0.91\n",
        "\n",
        "def test_acc_92():\n",
        "    acc = load_test_acc()\n",
        "    assert acc >= 0.92\n",
        "\n",
        "def test_softmax():\n",
        "    x = np.array([2.0, 1.0, 0.1])\n",
        "    y = softmax(x)\n",
        "\n",
        "    print(\"Softmax output:\", y)\n",
        "    print(\"Sum of outputs:\", np.sum(y))  # Should be 1.0\n",
        "    assert np.all(y >= 0) and np.all(y <= 1), \"Output not in [0,1]\"\n",
        "    assert np.isclose(np.sum(y), 1.0), \"Output does not sum to 1\"\n",
        "\n",
        "\n",
        "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))\n",
        "\n",
        "model.save('syam_model.h5')\n",
        "\n",
        "model = tf.keras.models.load_model('syam_model.h5')\n",
        "\n",
        "weights = model.get_weights()\n",
        "np.savez('syam_model.npz', *weights)\n",
        "\n",
        "with open('syam_model.json', 'w') as f:\n",
        "    f.write(model.to_json())\n",
        "\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=0)\n",
        "with open(OUTPUT_FILE, 'w') as f:\n",
        "    f.write(str(test_acc))\n",
        "\n",
        "print(f\"Training , save mode to syam_model.h5, syam_model.npz, syam_model.json\")\n",
        "print(f\"Test accuracy: {test_acc:.4f} disimpan di {OUTPUT_FILE}\")\n"
      ]
    }
  ]
}